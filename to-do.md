# TO-DO
## Admin and Doc
* create env
* create requirements.txt

## Main list 
* hierarchical SVM
* Hierarchical Softmax
	* LSTM
	* Bayesian
* transfer learning
	* fake sentence
	* fewer nr of intents (subset of classes)
* retraining word embeddings
* pruning of Bayesian LSTM
* NB bigrams
* Tail, Pooling, MaxPooling
* Data loader
	* FastText, Word2vec
* Data augmentation
	* synonyms from wordNet (synoniem set)

## SUGGESTIONS SL
* bootstrap full data
* confidence bounds obs/intent
* sklearn learning curve
	* test vs training score
	* robustness of models
* model fitting process with cv
	* x-axis different parameter settings
	* best model
* motivatie voor experimenten

## MAIL FF
* RNN / LSTM
    * Early stopping
    * Learning rate finder
    * Cosine Annealing
    * SGDR
    * Initialisation
    * Regularisation
    * Max Pool / Hybrid
    * Hierarchical
* Bayesian
    * weight pruning
* Data loader
    * Braun Data
    * Fast Text / Word2Vec
* Interesting extensions:
	* Attention model

## random notes
* svm tf-idf
* show CBoW_ave does not work (full datasets, SVM, W2V/GV/FT)
* plots in python

## writing
* Bayesian Neural Nets
* BB cv marie/braun - bayesian cross validation
* distilation

* cosine annealing
* SGDR
* dropout
* initialization
* transfer learning
	* braun to banking (vice versa)